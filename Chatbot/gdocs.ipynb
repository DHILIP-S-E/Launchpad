{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google drive files to interact with llm's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credentials path setup is very important to access all the google drive files. Consists of several steps to do in google cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GoogleDriveLoader\n",
    "from langchain_groq import ChatGroq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\DHILIP\\Downloads\\client_secret_753799051727-451fo930k7rn0soknm10ljdabputojf5.apps.googleusercontent.com.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling GoogleDriveLoader from langchain by specifying document id's and credentials for authentication. Folder id also can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GoogleDriveLoader(document_ids=[\"1XBK65tZ6h_pza7f994YhDzD4VIWxagy1\"],\n",
    "                            credentials_path=R\"C:\\Users\\DHILIP\\.credentials\\client_secret_753799051727-fcsk6q8ckmveisgg1ii3memja9rrbhsj.apps.googleusercontent.com.json\")\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: <HttpError 403 when requesting https://www.googleapis.com/drive/v3/files/1XBK65tZ6h_pza7f994YhDzD4VIWxagy1/export?mimeType=text%2Fplain&alt=media returned \"Export only supports Docs Editors files.\". Details: \"[{'message': 'Export only supports Docs Editors files.', 'domain': 'global', 'reason': 'fileNotExportable'}]\">\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.google.com/document/d/1XBK65tZ6h_pza7f994YhDzD4VIWxagy1/edit', 'title': 'Principles of Data Science.docx', 'when': '2024-10-21T17:02:20.912Z'}, page_content='')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Langsmith tracking (Observable)\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_VR\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ChatGroq Inference to fasten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groqllm = ChatGroq(model=\"llama3-70b-8192\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"There is no text to summarize. The input is an empty string.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"No text provided.\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(groqllm,chain_type=\"map_reduce\",verbose=True)\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatgroq performed it in less than 3 sec. This is the absolute usecase of this inference engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is Neural Network\" # Querying the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "\n",
      "Human: what is Neural Network\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A neural network is a machine learning model inspired by the structure and function of the human brain. It\\'s a complex system of interconnected nodes or \"neurons\" that process and transmit information.\\n\\nIn a neural network, each neuron receives one or more inputs, performs a computation on those inputs, and then sends the output to other neurons. This process allows the network to learn and represent complex relationships between inputs and outputs.\\n\\nA neural network typically consists of three types of layers:\\n\\n1. **Input layer**: This layer receives the input data, such as images, sound, or text.\\n2. **Hidden layers**: These layers perform complex computations on the input data, allowing the network to learn and represent more abstract concepts.\\n3. **Output layer**: This layer generates the final output of the network, based on the computations performed in the hidden layers.\\n\\nNeural networks can be trained using large datasets, allowing them to learn and improve their performance over time. They\\'re commonly used in applications such as:\\n\\n* Image and speech recognition\\n* Natural language processing\\n* Game playing (e.g., chess, Go)\\n* Autonomous vehicles\\n* Recommendation systems\\n\\nThere are many types of neural networks, including:\\n\\n* **Feedforward networks**: The most common type, where data flows only in one direction, from input to output.\\n* **Recurrent neural networks (RNNs)**: These networks have feedback connections, allowing data to flow in a loop, enabling them to process sequential data.\\n* **Convolutional neural networks (CNNs)**: These networks are designed to process data with grid-like topology, such as images.\\n\\nNeural networks have many advantages, including their ability to learn and improve over time, handle large datasets, and make accurate predictions. However, they can also be computationally expensive, require large amounts of data, and be difficult to interpret.\\n\\nI hope this helps! Do you have any specific questions about neural networks?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(groqllm,chain_type=\"stuff\",verbose=True)\n",
    "chain.run(input_documents = docs, question = query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gave good results after interacting with the document. Langchain has the ability to hold the prompts.\n",
    "\n",
    "If we want to interact with another document we can simply extend the initial doc. It holds all the base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
